{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68f16fa-9333-47a8-8a3e-b0a2d06dcfc6",
   "metadata": {},
   "source": [
    "## Neural Network Quantization\n",
    "\n",
    "---\n",
    "\n",
    "### Before we begin...\n",
    "\n",
    "For a well-rounded understanding of this topic, I highly recommend the lectures [TinyML and Efficient Deep Learning Computing by MiT HAN.LAb](https://hanlab.mit.edu/courses/2024-fall-65940). This is a fantastic course made by a world-level expert, Professor Song Han from MIT EECS. Although you will be able to understanding all the approaches I present in the repository, it  will be more effective to supplement the samples with a detailed explanation of the topic. \n",
    "\n",
    "Broadly speaking, quantization is a technique that converts a neural network from high-precision arithmetic (like 32-bit floating point) to low-precision (like 8-bit integers). This process addresses several critical needs in production deployment:\n",
    "\n",
    "1. __Faster Inference__: Low-precision operations are computationally cheaper and can be heavily optimized on modern hardware.\n",
    "2. __Smaller Model Size__: Reduced precision drastically cuts storage requirements, enabling deployment on resource-constrained devices.\n",
    "3. __Lower Energy Consumption and Carbon Footprint__: Efficient computation and reduced memory bandwidth directly translate to less power usage, which is crucial at a global scale.\n",
    "\n",
    "As a result, quantization enables:\n",
    "1. Efficient execution on specific hardware, especially on edge devices with limited resources.\n",
    "2. A carefully managed trade-off between model accuracy and computational efficiency.\n",
    "\n",
    "### Remember!\n",
    "\n",
    "A fundamental principle in computer architecture and performance optimization is:\n",
    "> *Compute is cheap, memory access is expensive*.\n",
    "\n",
    "In other words, the cost of moving data between different levels of memory (e.g., from RAM to cache levels) often dominates performance. \n",
    "Minimizing this data transfer is a cornerstone of efficient algorithm and system design.\n",
    "\n",
    "Moreover, quantization is an application-oriented research topic that is highly driven by the needs of the computing industry. It is deeply interconnected with many other computer science disciplines, from hardware design to compiler theory.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae203d90bcceab73",
   "metadata": {},
   "source": [
    "## Asymmetric (Affine) Linear Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee716b613197240",
   "metadata": {},
   "source": [
    "In this notebook we will go through asymmetric linear quantization steps. Our goal is to compress ML model from __32-bit floating point__ precision to a __lower one__ preserving the most of the model acuracy.\n",
    "\n",
    "Quantization approach helps to reduce excessive use of memory to store, read and apply ML models.\n",
    "\n",
    "__Linear Quantization__ suggests that we can store quantized model weights along with small amount of parameters that helps to restore quantized weights as much as possible into the original form with higher bit precision via set of linear operations. The simplest way to do that is to store some scaling coefficients and track zero point between higher and lower precision weights.\n",
    "\n",
    "*Note: we can quantize not only weights but __activations__ as well, we will cover some algorithms working with activations quantization in further examples.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af38a8633778b7",
   "metadata": {},
   "source": [
    "In __Asymmetric Linear quantization__ we track quantized weights __scaling coefficients__ and __zero point__ location for a quantized range of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a03df72a3e9317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchao\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from watermark import watermark\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6383de0-241a-42e7-b9d6-d774fce85eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2025-10-26T21:05:21.834463+03:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.3\n",
      "IPython version      : 9.6.0\n",
      "\n",
      "Compiler    : GCC 13.3.0\n",
      "OS          : Linux\n",
      "Release     : 6.14.0-33-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n",
      "numpy      : 2.3.4\n",
      "torch      : 2.9.0\n",
      "torchvision: 0.24.0\n",
      "sklearn    : 1.7.2\n",
      "matplotlib : 3.10.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(watermark())\n",
    "print(watermark(packages=\"numpy,torch,torchvision,sklearn,matplotlib\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582306d-f303-4813-ab2f-2afeede1203e",
   "metadata": {},
   "source": [
    "### Example 1. Wine classifier with dense neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05e0ec0-a735-479c-9ede-e945d79adb7c",
   "metadata": {},
   "source": [
    "In this example we will use [wine](https://archive.ics.uci.edu/dataset/109/wine) tabular dataset and a dense neural network to classify types of wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0250e1-c397-401b-8209-d44d24ab7554",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "test_size = 0.2\n",
    "\n",
    "np.random.seed(seed)\n",
    "data = datasets.load_wine()\n",
    "\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "y_train_enc = enc.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_enc = enc.transform(y_test.reshape(-1, 1))\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a916f5-cd8c-4541-be8a-a01e57e62ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13) (142, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sc.shape, y_train_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3223a46-7557-453f-9d9e-3f700f27f16f",
   "metadata": {},
   "source": [
    "### 1.1 Example: Numpy implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a80928-402f-4aa5-aa12-b21fd81dd623",
   "metadata": {},
   "source": [
    "#### Preparing neural network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ea71b5-ba7a-4549-b51e-e87bc5c65b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet:\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_size: int, \n",
    "        hidden_size: int, \n",
    "        output_size: int\n",
    "    ):\n",
    "        # input_size, number of features in our dataset\n",
    "        # hidden_size, hidden feature vector\n",
    "        # output_size, the number of classes in our task\n",
    "        self.W1 = None\n",
    "        self.b1 = None\n",
    "        self.W2 = None\n",
    "        self.b2 = None\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        # First layer with bias\n",
    "        self.W1 = np.random.randn(input_size, hidden_size).astype(np.float32)\n",
    "        self.b1 = np.random.randn(1, hidden_size).astype(np.float32)\n",
    "        \n",
    "        # Second layer with bias\n",
    "        self.W2 = np.random.randn(hidden_size, output_size).astype(np.float32)\n",
    "        self.b2 = np.random.randn(1, output_size).astype(np.float32)\n",
    "\n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        # Apply weights: z1 = W1X + b1\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        # Apply ReLU activation function: a1 = relu(z1)\n",
    "        self.a1 = np.maximum(0, self.z1)\n",
    "        # Apply weights: z2 = W2a1 + b2\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        # Aply softmax activation: a2 = softmax(z2)\n",
    "        exp_z2 = np.exp(self.z2)\n",
    "        self.a2 = exp_z2 / np.sum(exp_z2, axis=1, keepdims=True)\n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, X: np.ndarray, y: np.ndarray, learning_rate: float) -> None:\n",
    "        \"\"\"\n",
    "        Lets write details how we actually calculate derivates for our model.\n",
    "        \n",
    "        L- loss function, the result of our forward calculation.\n",
    "        \n",
    "        dL/dz2 = a2 - y\n",
    "        \n",
    "            dL/dW2 = dL/dz2 * dz2/dW2 = (a2 - y) * a1\n",
    "            dL/db2 = dL/dz2 * dz2/db2 = (a2 - y) * 1\n",
    "\n",
    "            dL/da1 = dL/dz2 * dz2/da1 = (a2 - y) * W2\n",
    "\n",
    "                dL/dz1 = dL/da1 * da1/dz1 =  (a2 - y) * W2 * 1_(z1 > 0)\n",
    "\n",
    "                    dL/dW1 = dL/dz1 * dz1/dW1 = (a2 - y) * W2 * 1_(z1 > 0) * X\n",
    "                    dL/db1 = dL/dz1 * dz1/db1 = (a2 - y) * W2 * 1_(z1 > 0)\n",
    "        \"\"\"\n",
    "        m = X.shape[0]\n",
    "\n",
    "        dz2 = self.a2 - y                                  # dL/dz2 \n",
    "        dW2 = np.dot(self.a1.T, dz2) / m                   # dL/dW2\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / m       # dL/db2 \n",
    "        da1 = np.dot(dz2, self.W2.T)                       # dL/da1\n",
    "        \n",
    "        dz1 = da1 * (self.z1 > 0)                          # dL/dz1, Gradient for ReLU with indicator\n",
    "        dW1 = np.dot(X.T, dz1) / m                         # dL/dW1\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / m       # dL/db1\n",
    "\n",
    "        # Update weights with fixed learning_rate with respect to their derivatives\n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42fe35f3-49dc-46ce-9b39-2f0b93bb36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "n_features = X.shape[1]             # 13 features, 13 table columns\n",
    "input_size = n_features             # Features are our input size of one sample\n",
    "hidden_size = 100                   # Hidden size is our hidden dimension. \n",
    "output_size = len(np.unique(y))     # Output size is defined via our categories\n",
    "\n",
    "# Set model training configuration\n",
    "epochs = 200     # Total epochs\n",
    "batch_size = 10  # How many samples we use in a mini-batch training\n",
    "lr = 0.1         # Learning rate is constant for simplicity\n",
    "eps = 1e-8       # Constant for numerical stability\n",
    "show_epochs = 10 # For verbose output\n",
    "train_size = len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790cc63b-c879-4f51-a6b2-f7a9834b4ab5",
   "metadata": {},
   "source": [
    "Lets train our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcc1e1c3-2ec6-45b1-9a2d-06c50054145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NNet(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b7d74b2-737b-465d-822c-f3f2f1960bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model info:\n",
      "dim(W1): (13, 100)\n",
      "dim(b1): (1, 100)\n",
      "dim(W2): (100, 3)\n",
      "dim(b2): (1, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_info = {\n",
    "    \"W1\": model.W1.shape,\n",
    "    \"b1\": model.b1.shape,\n",
    "    \"W2\": model.W2.shape,\n",
    "    \"b2\": model.b2.shape,\n",
    "}\n",
    "print(\"Model info:\\n\" + \"\".join([f\"dim({k}): {v}\\n\" for k, v in model_info.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d77fd2a9-bff4-49a9-94bb-07bdd88776be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train loss: 34.80452084764922\n",
      "Epoch: 10. Train loss: 0.001660566730564671\n",
      "Epoch: 20. Train loss: 0.0009475190943517911\n",
      "Epoch: 30. Train loss: 0.0006958735681107859\n",
      "Epoch: 40. Train loss: 0.0005595339075997498\n",
      "Epoch: 50. Train loss: 0.0004725040701494334\n",
      "Epoch: 60. Train loss: 0.00041178088309021623\n",
      "Epoch: 70. Train loss: 0.0003669436213747717\n",
      "Epoch: 80. Train loss: 0.00033249625635077925\n",
      "Epoch: 90. Train loss: 0.00030524011818419103\n",
      "Epoch: 100. Train loss: 0.0002831695550347456\n",
      "Epoch: 110. Train loss: 0.00026495946563865377\n",
      "Epoch: 120. Train loss: 0.00024970139180467975\n",
      "Epoch: 130. Train loss: 0.00023674328596567416\n",
      "Epoch: 140. Train loss: 0.00022561188672422084\n",
      "Epoch: 150. Train loss: 0.0002159467793310257\n",
      "Epoch: 160. Train loss: 0.00020747418316025893\n",
      "Epoch: 170. Train loss: 0.00019998341468951841\n",
      "Epoch: 180. Train loss: 0.00019330689638822222\n",
      "Epoch: 190. Train loss: 0.00018731311547128917\n"
     ]
    }
   ],
   "source": [
    "model.init_weights()\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  loss_accum = 0\n",
    "  for i in range(0, train_size, batch_size):\n",
    "    X_batch = X_train_sc[i: i + batch_size, :]\n",
    "    y_batch = np.array(y_train_enc[i: i + batch_size, :].todense())\n",
    "\n",
    "    y_pred = model.forward(X_batch)\n",
    "    ce_loss = -np.mean( np.sum(np.multiply(y_batch, np.log(y_pred + eps)), axis=1) )\n",
    "    model.backward(X_batch, y_batch, lr)\n",
    "    loss_accum += ce_loss\n",
    "  loss_log.append(loss_accum)\n",
    "  if epoch % show_epochs == 0:\n",
    "    print(f\"Epoch: {epoch}. Train loss: {loss_accum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd1e556e-8f8b-4add-946a-671de7ef4f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 297,
       "width": 380
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(4 ,3))\n",
    "plt.plot(np.log(loss_log))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"log(Loss per epoch)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d157a62-9759-4591-95e7-34b969a2c4ef",
   "metadata": {},
   "source": [
    "Evaluate model on a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c8afbe5-7781-4b07-8c7a-7db1dc294dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.89      1.00      0.94         8\n",
      "     class_1       0.91      0.91      0.91        11\n",
      "     class_2       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.93      0.95      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = np.argmax(model.forward(X_test_sc), axis=1)\n",
    "print(classification_report(y_test, y_pred_test, target_names=data.target_names))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef0d4b0-14a6-4cec-b3d9-9549ce3871bc",
   "metadata": {},
   "source": [
    "Everybody wishes to get such metrics on a real data 😄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08a88b-f2f6-45b2-befd-fe9c687f1493",
   "metadata": {},
   "source": [
    "Now when we have the prepared model we can apply quantization. But before doing that lets measure current model storage assuming that we have 32-bit floating point weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c55c1ba-bcbc-4a0b-9a32-c543005f818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_storage(model_obj: object, num_bits: int) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the total storage size of a model in bytes.\n",
    "    NB!!! Without storage need for metadata: scaling coefficients and zero point\n",
    "\n",
    "    Parameters:\n",
    "        model (NNet): The neural network model with weights and biases.\n",
    "        num_bits (int): The bit precision (e.g., 32 for FP32, 8 for INT8).\n",
    "\n",
    "    Returns:\n",
    "        int: Total storage size in bytes.\n",
    "    \"\"\"\n",
    "    total_params = 0\n",
    "\n",
    "    # Count parameters for each layer\n",
    "    total_params += np.prod(model_obj.W1.shape) + np.prod(model_obj.b1.shape)\n",
    "    total_params += np.prod(model_obj.W2.shape) + np.prod(model_obj.b2.shape)\n",
    "\n",
    "    # Calculate storage in bytes\n",
    "    total_bits = total_params * num_bits\n",
    "    total_bytes = total_bits // 8\n",
    "\n",
    "    return total_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "023d15be-a58c-405d-a0de-f9cc357b36c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model size is 6.65KB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial model size is {calculate_model_storage(model, 32) / 1024:.2f}KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d43b5a2-f263-4ea7-a1ba-45f671754eaf",
   "metadata": {},
   "source": [
    "We will store this information for further comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23e7eb07-d928-4b3b-8e25-15330cfe9078",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_report = classification_report(y_test, y_pred_test, target_names=data.target_names, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16b23060-1087-4238-abf5-9c02aac3aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    (\n",
    "        \"fp32\",\n",
    "        float(initial_report[\"macro avg\"][\"f1-score\"]),\n",
    "        float(initial_report[\"macro avg\"][\"recall\"]),\n",
    "        float(initial_report[\"macro avg\"][\"precision\"]),\n",
    "        calculate_model_storage(model, 32) / 1024, # Weights size in KB\n",
    "        0, # Quantization squared error\n",
    "    ) \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f614ad-45e9-4f68-b282-4d07aa19407b",
   "metadata": {},
   "source": [
    "#### Apply quantization\n",
    "\n",
    "\n",
    "We will stick to the following procedure to pick the best model from the quantized candidates:\n",
    "\n",
    "1. Apply initial cross-layer equalization, CLE\n",
    "2. Apply linear quantization\n",
    "3. Calculate quantization error as MSE between initial FP32 weights and dequantized weights calculated from lower precision\n",
    "4. Evaluate model storage and accuracy\n",
    "\n",
    "*Note: CLE is another topic closely related to qunatization procedures. You can learn more in paper [Data-Free Quantization\n",
    "Through Weight Equalization and Bias Correction](https://arxiv.org/pdf/1906.04721)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a43d45d3-c7fa-4bfd-9712-dd11d1e82e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_preicions_in_bits = (8, 6, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56ba29ed-babf-4d3e-825e-bfd78a22e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_layer_equalization(W1: np.ndarray, W2: np.ndarray, b1: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    Normalize the weights across two consecutive layers to balance their scales.\n",
    "    Adjusts W1, W2, and b1 in place to equalize the activation ranges.\n",
    "    \"\"\"\n",
    "    # We use weights dimension order (in_features, out_features) in this simple setting.\n",
    "    r1 = np.max(np.abs(W1), axis=0)  # Max abs values in W1, axis=1 means we aggregate values across inputs\n",
    "    r2 = np.max(np.abs(W2), axis=1)  # Max abs values in W2, axis=0 means we aggregate values across outputs\n",
    "\n",
    "    s = r1 / (r2 + 1e-8)\n",
    "    # print(f\"CLE scaling factors: {s}\")\n",
    "    \n",
    "    for i in range(W1.shape[1]):\n",
    "        W1[:, i] = W1[:, i] / s[i]\n",
    "        b1[0][i] = b1[0][i] / s[i]\n",
    "        W2[i, :] = W2[i, :] * s[i]\n",
    "\n",
    "    return W1, W2, b1\n",
    "     \n",
    "\n",
    "def quantize_tensor(tensor: np.ndarray, num_bits: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Apply asymmetric linear quantization\n",
    "    \"\"\"\n",
    "\n",
    "    qmin = -(2 ** (num_bits - 1))     # Minimum value in quantized range\n",
    "    qmax = (2 ** (num_bits - 1)) - 1. # Maximum value in quantized range\n",
    "\n",
    "    min_val = np.min(tensor)          # Minimum real value of a tensor\n",
    "    max_val = np.max(tensor)          # Maximum real value of a tensor\n",
    "\n",
    "    scale = (max_val - min_val) / (qmax - qmin) # Scaling factor\n",
    "    zero_point = qmin - min_val / scale         # Zero point location for a quantized range\n",
    "\n",
    "    # These matrices can be stored along with scaling factors and zero point for dequantization\n",
    "    quantized = np.round(zero_point + tensor / scale).clip(qmin, qmax).astype(int)\n",
    "    dequantized = scale * (quantized - zero_point)\n",
    "\n",
    "    return quantized, dequantized, scale, zero_point\n",
    "\n",
    "\n",
    "def get_quant_mse(x1: np.ndarray, x2: np.ndarray, precision: int = 4) -> float:\n",
    "  return np.round(np.sum( (x1 - x2)**2), precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46b2e67d-4079-436e-91dc-8e81e97011d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Qunatization with Bits: 8\n",
      "#Original FP32 W1:\n",
      "[[-0.5420247  -0.17215796 -0.4775285  ... -0.23556532 -0.16103874\n",
      "  -0.1501477 ]\n",
      " [ 0.15514757  0.37640822 -0.8304614  ...  0.03485452  0.00406086\n",
      "  -0.10569131]\n",
      " [ 1.5605261   0.42767206  0.06610699 ... -1.1828731  -0.28799695\n",
      "   0.57866275]\n",
      " ...\n",
      " [ 0.38066596  0.3469791   0.19245772 ... -0.7721957  -0.17893527\n",
      "  -0.497879  ]\n",
      " [-1.321151    0.8399943   0.5546144  ...  0.18353902  0.07889172\n",
      "   0.2625545 ]\n",
      " [-0.46748447 -0.465602   -0.02235018 ... -0.30418375  0.14572665\n",
      "   0.64380074]]\n",
      "#Quantized W1 with 8 bits:\n",
      "[[-32 -15 -29 ... -18 -14 -14]\n",
      " [  1  11 -46 ...  -5  -6 -12]\n",
      " [ 68  14  -3 ... -63 -20  21]\n",
      " ...\n",
      " [ 12  10   3 ... -43 -15 -30]\n",
      " [-69  33  20 ...   2  -3   6]\n",
      " [-29 -29  -8 ... -21   0  24]]\n",
      "#Dequantized W1:\n",
      "[[-0.53670628 -0.17849387 -0.47349233 ... -0.24170782 -0.15742255\n",
      "  -0.15742255]\n",
      " [ 0.15864723  0.36936041 -0.83170474 ...  0.03221932  0.011148\n",
      "  -0.11527991]\n",
      " [ 1.57042557  0.43257437  0.07436196 ... -1.18991716 -0.28385046\n",
      "   0.5800736 ]\n",
      " ...\n",
      " [ 0.39043173  0.3482891   0.20078987 ... -0.76849079 -0.17849387\n",
      "  -0.49456365]\n",
      " [-1.31634507  0.83292942  0.55900228 ...  0.17971855  0.07436196\n",
      "   0.26400382]\n",
      " [-0.47349233 -0.47349233 -0.03099464 ... -0.30492178  0.13757591\n",
      "   0.64328756]]\n",
      "Quantization MSE: 0.0616\n",
      "INT8 Model Storage: 1.66 KB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.89      1.00      0.94         8\n",
      "     class_1       0.91      0.91      0.91        11\n",
      "     class_2       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.93      0.95      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "### Qunatization with Bits: 6\n",
      "#Original FP32 W1:\n",
      "[[-0.5420247  -0.17215796 -0.4775285  ... -0.23556532 -0.16103874\n",
      "  -0.1501477 ]\n",
      " [ 0.15514757  0.37640822 -0.8304614  ...  0.03485452  0.00406086\n",
      "  -0.10569131]\n",
      " [ 1.5605261   0.42767206  0.06610699 ... -1.1828731  -0.28799695\n",
      "   0.57866275]\n",
      " ...\n",
      " [ 0.38066596  0.3469791   0.19245772 ... -0.7721957  -0.17893527\n",
      "  -0.497879  ]\n",
      " [-1.321151    0.8399943   0.5546144  ...  0.18353902  0.07889172\n",
      "   0.2625545 ]\n",
      " [-0.46748447 -0.465602   -0.02235018 ... -0.30418375  0.14572665\n",
      "   0.64380074]]\n",
      "#Quantized W1 with 6 bits:\n",
      "[[ -8  -4  -8 ...  -5  -4  -4]\n",
      " [  0   2 -12 ...  -2  -2  -3]\n",
      " [ 16   3  -1 ... -16  -5   5]\n",
      " ...\n",
      " [  2   2   0 ... -11  -4  -8]\n",
      " [-17   8   5 ...   0  -1   1]\n",
      " [ -7  -7  -2 ...  -6   0   6]]\n",
      "#Dequantized W1:\n",
      "[[-5.12624921e-01 -1.71470257e-01 -5.12624921e-01 ... -2.56758923e-01\n",
      "  -1.71470257e-01 -1.71470257e-01]\n",
      " [ 1.69684408e-01  3.40261740e-01 -8.53779586e-01 ... -8.92924287e-04\n",
      "  -8.92924287e-04 -8.61815905e-02]\n",
      " [ 1.53430307e+00  4.25550407e-01  8.43957419e-02 ... -1.19493425e+00\n",
      "  -2.56758923e-01  5.96127739e-01]\n",
      " ...\n",
      " [ 3.40261740e-01  3.40261740e-01  1.69684408e-01 ... -7.68490920e-01\n",
      "  -1.71470257e-01 -5.12624921e-01]\n",
      " [-1.28022292e+00  8.51993738e-01  5.96127739e-01 ...  1.69684408e-01\n",
      "   8.43957419e-02  2.54973074e-01]\n",
      " [-4.27336255e-01 -4.27336255e-01 -8.92924287e-04 ... -3.42047589e-01\n",
      "   1.69684408e-01  6.81416405e-01]]\n",
      "Quantization MSE: 0.992\n",
      "INT6 Model Storage: 1.25 KB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.89      1.00      0.94         8\n",
      "     class_1       0.91      0.91      0.91        11\n",
      "     class_2       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.93      0.95      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "### Qunatization with Bits: 4\n",
      "#Original FP32 W1:\n",
      "[[-0.5420247  -0.17215796 -0.4775285  ... -0.23556532 -0.16103874\n",
      "  -0.1501477 ]\n",
      " [ 0.15514757  0.37640822 -0.8304614  ...  0.03485452  0.00406086\n",
      "  -0.10569131]\n",
      " [ 1.5605261   0.42767206  0.06610699 ... -1.1828731  -0.28799695\n",
      "   0.57866275]\n",
      " ...\n",
      " [ 0.38066596  0.3469791   0.19245772 ... -0.7721957  -0.17893527\n",
      "  -0.497879  ]\n",
      " [-1.321151    0.8399943   0.5546144  ...  0.18353902  0.07889172\n",
      "   0.2625545 ]\n",
      " [-0.46748447 -0.465602   -0.02235018 ... -0.30418375  0.14572665\n",
      "   0.64380074]]\n",
      "#Quantized W1 with 4 bits:\n",
      "[[-2 -1 -2 ... -2 -1 -1]\n",
      " [ 0  0 -3 ... -1 -1 -1]\n",
      " [ 4  0 -1 ... -4 -2  1]\n",
      " ...\n",
      " [ 0  0  0 ... -3 -1 -2]\n",
      " [-5  1  1 ...  0 -1  0]\n",
      " [-2 -2 -1 ... -2  0  1]]\n",
      "#Dequantized W1:\n",
      "[[-0.41027841 -0.052066   -0.41027841 ... -0.41027841 -0.052066\n",
      "  -0.052066  ]\n",
      " [ 0.30614642  0.30614642 -0.76849082 ... -0.052066   -0.052066\n",
      "  -0.052066  ]\n",
      " [ 1.73899606  0.30614642 -0.052066   ... -1.12670323 -0.41027841\n",
      "   0.66435883]\n",
      " ...\n",
      " [ 0.30614642  0.30614642  0.30614642 ... -0.76849082 -0.052066\n",
      "  -0.41027841]\n",
      " [-1.48491564  0.66435883  0.66435883 ...  0.30614642 -0.052066\n",
      "   0.30614642]\n",
      " [-0.41027841 -0.41027841 -0.052066   ... -0.41027841  0.30614642\n",
      "   0.66435883]]\n",
      "Quantization MSE: 18.1014\n",
      "INT4 Model Storage: 0.83 KB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.89      1.00      0.94         8\n",
      "     class_1       1.00      0.91      0.95        11\n",
      "     class_2       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.96      0.97      0.96        36\n",
      "weighted avg       0.98      0.97      0.97        36\n",
      "\n",
      "### Qunatization with Bits: 2\n",
      "#Original FP32 W1:\n",
      "[[-0.5420247  -0.17215796 -0.4775285  ... -0.23556532 -0.16103874\n",
      "  -0.1501477 ]\n",
      " [ 0.15514757  0.37640822 -0.8304614  ...  0.03485452  0.00406086\n",
      "  -0.10569131]\n",
      " [ 1.5605261   0.42767206  0.06610699 ... -1.1828731  -0.28799695\n",
      "   0.57866275]\n",
      " ...\n",
      " [ 0.38066596  0.3469791   0.19245772 ... -0.7721957  -0.17893527\n",
      "  -0.497879  ]\n",
      " [-1.321151    0.8399943   0.5546144  ...  0.18353902  0.07889172\n",
      "   0.2625545 ]\n",
      " [-0.46748447 -0.465602   -0.02235018 ... -0.30418375  0.14572665\n",
      "   0.64380074]]\n",
      "#Quantized W1 with 2 bits:\n",
      "[[-1 -1 -1 ... -1 -1 -1]\n",
      " [ 0  0 -1 ... -1 -1 -1]\n",
      " [ 0  0 -1 ... -1 -1  0]\n",
      " ...\n",
      " [ 0  0  0 ... -1 -1 -1]\n",
      " [-1  0  0 ...  0 -1  0]\n",
      " [-1 -1 -1 ... -1  0  0]]\n",
      "#Dequantized W1:\n",
      "[[-0.76849096 -0.76849096 -0.76849096 ... -0.76849096 -0.76849096\n",
      "  -0.76849096]\n",
      " [ 1.02257103  1.02257103 -0.76849096 ... -0.76849096 -0.76849096\n",
      "  -0.76849096]\n",
      " [ 1.02257103  1.02257103 -0.76849096 ... -0.76849096 -0.76849096\n",
      "   1.02257103]\n",
      " ...\n",
      " [ 1.02257103  1.02257103  1.02257103 ... -0.76849096 -0.76849096\n",
      "  -0.76849096]\n",
      " [-0.76849096  1.02257103  1.02257103 ...  1.02257103 -0.76849096\n",
      "   1.02257103]\n",
      " [-0.76849096 -0.76849096 -0.76849096 ... -0.76849096  1.02257103\n",
      "   1.02257103]]\n",
      "Quantization MSE: 566.2275\n",
      "INT2 Model Storage: 0.42 KB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.67      0.75      0.71         8\n",
      "     class_1       0.77      0.91      0.83        11\n",
      "     class_2       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.81      0.83      0.81        36\n",
      "weighted avg       0.86      0.83      0.84        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for bits in weights_preicions_in_bits:\n",
    "\n",
    "  print(f\"### Qunatization with Bits: {bits}\")\n",
    "\n",
    "  model_quantized = copy.deepcopy(model)\n",
    "\n",
    "  # Step 1: Apply CLE\n",
    "  W1, W2, b1 = cross_layer_equalization(model_quantized.W1, model_quantized.W2, model_quantized.b1)\n",
    "  b2 = model_quantized.b2\n",
    "\n",
    "  # Step 2: Quantize weights and biases of the model\n",
    "  q_W1, dq_W1, scale_W1, zp_W1 = quantize_tensor(W1, bits)\n",
    "  q_b1, dq_b1, scale_b1, zp_b1 = quantize_tensor(b1, bits)\n",
    "  q_W2, dq_W2, scale_W2, zp_W2 = quantize_tensor(W2, bits)\n",
    "  q_b2, dq_b2, scale_b2, zp_b2 = quantize_tensor(b2, bits)\n",
    "  print(f\"#Original FP32 W1:\\n{W1}\\n#Quantized W1 with {bits} bits:\\n{q_W1}\\n#Dequantized W1:\\n{dq_W1}\")\n",
    "  quant_mse = np.round(get_quant_mse(dq_W1, W1) + get_quant_mse(dq_W2, W2) + get_quant_mse(dq_b2, b2) + get_quant_mse(dq_b1, b1), 4)\n",
    "  print(f\"Quantization MSE: {quant_mse}\")\n",
    "\n",
    "  # Step 3: Assign new weights to the model\n",
    "  model_quantized.W1 = dq_W1\n",
    "  model_quantized.b1 = dq_b1\n",
    "  model_quantized.W2 = dq_W2\n",
    "  model_quantized.b2 = dq_b2\n",
    "\n",
    "  storage_kb = calculate_model_storage(model, num_bits=bits) / 1024\n",
    "  print(f\"INT{bits} Model Storage: {storage_kb :.2f} KB\")\n",
    "  y_pred_test_quant = np.argmax(model_quantized.forward(X_test_sc), axis=1)\n",
    "  report = classification_report(y_test, y_pred_test_quant, target_names=data.target_names)\n",
    "  report_dict = classification_report(y_test, y_pred_test_quant, target_names=data.target_names, output_dict=True)\n",
    "  print(report)\n",
    "\n",
    "  METRICS.append(\n",
    "      (\n",
    "              f\"Q_{bits}bit\", \n",
    "              float(report_dict[\"macro avg\"][\"f1-score\"]),\n",
    "              float(report_dict[\"macro avg\"][\"recall\"]),\n",
    "              float(report_dict[\"macro avg\"][\"precision\"]),\n",
    "              float(storage_kb),\n",
    "              float(quant_mse),\n",
    "    )\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a06cf5b-fa3b-438b-ba5b-0f68604d7df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fp32',\n",
       "  0.9399881164587046,\n",
       "  0.9500891265597149,\n",
       "  0.9326599326599326,\n",
       "  np.float64(6.65234375),\n",
       "  0),\n",
       " ('Q_8bit',\n",
       "  0.9399881164587046,\n",
       "  0.9500891265597149,\n",
       "  0.9326599326599326,\n",
       "  1.6630859375,\n",
       "  0.0616),\n",
       " ('Q_6bit',\n",
       "  0.9399881164587046,\n",
       "  0.9500891265597149,\n",
       "  0.9326599326599326,\n",
       "  1.2470703125,\n",
       "  0.992),\n",
       " ('Q_4bit',\n",
       "  0.9645191409897292,\n",
       "  0.9696969696969697,\n",
       "  0.9629629629629629,\n",
       "  0.8310546875,\n",
       "  18.1014),\n",
       " ('Q_2bit',\n",
       "  0.8141471642420409,\n",
       "  0.8275401069518716,\n",
       "  0.8119658119658121,\n",
       "  0.4150390625,\n",
       "  566.2275)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8027c4a4-e8da-4045-91e4-8faa5d0eeef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(METRICS, columns=[\"Weights\", \"macro_avg_f1\", \"macro_avg_recall\", \"macro_avg_precision\", \"Kb\", \"MSE\"])\n",
    "# Simple efficiency metric\n",
    "# It shows how much model accuracy nominated in `macro_avg_f1` we store per one Kb of the model storage\n",
    "df_results[\"macro_avg_f1_per_Kb\"] = df_results[\"macro_avg_f1\"] / df_results[\"Kb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ae665d0-570b-456c-86ce-d28142cdd1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights</th>\n",
       "      <th>macro_avg_f1</th>\n",
       "      <th>macro_avg_recall</th>\n",
       "      <th>macro_avg_precision</th>\n",
       "      <th>Kb</th>\n",
       "      <th>MSE</th>\n",
       "      <th>macro_avg_f1_per_Kb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fp32</td>\n",
       "      <td>0.939988</td>\n",
       "      <td>0.950089</td>\n",
       "      <td>0.932660</td>\n",
       "      <td>6.652344</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.141302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q_8bit</td>\n",
       "      <td>0.939988</td>\n",
       "      <td>0.950089</td>\n",
       "      <td>0.932660</td>\n",
       "      <td>1.663086</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.565207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q_6bit</td>\n",
       "      <td>0.939988</td>\n",
       "      <td>0.950089</td>\n",
       "      <td>0.932660</td>\n",
       "      <td>1.247070</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.753757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q_4bit</td>\n",
       "      <td>0.964519</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.831055</td>\n",
       "      <td>18.1014</td>\n",
       "      <td>1.160596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q_2bit</td>\n",
       "      <td>0.814147</td>\n",
       "      <td>0.827540</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.415039</td>\n",
       "      <td>566.2275</td>\n",
       "      <td>1.961616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Weights  macro_avg_f1  macro_avg_recall  macro_avg_precision        Kb  \\\n",
       "0    fp32      0.939988          0.950089             0.932660  6.652344   \n",
       "1  Q_8bit      0.939988          0.950089             0.932660  1.663086   \n",
       "2  Q_6bit      0.939988          0.950089             0.932660  1.247070   \n",
       "3  Q_4bit      0.964519          0.969697             0.962963  0.831055   \n",
       "4  Q_2bit      0.814147          0.827540             0.811966  0.415039   \n",
       "\n",
       "        MSE  macro_avg_f1_per_Kb  \n",
       "0    0.0000             0.141302  \n",
       "1    0.0616             0.565207  \n",
       "2    0.9920             0.753757  \n",
       "3   18.1014             1.160596  \n",
       "4  566.2275             1.961616  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c0785-7ac2-473a-b7fd-f075767fa5cd",
   "metadata": {},
   "source": [
    "On top of that, we should keep the following linear coefficients for later weights dequantization during inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46f1602d-7e71-4499-806e-aa9c727db060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scale_W1': np.float32(1.791062),\n",
       " 'zp_W1': np.float32(-0.57093),\n",
       " 'scale_b1': np.float32(1.5382051),\n",
       " 'zp_b1': np.float32(-0.6835902),\n",
       " 'scale_W2': np.float32(1.9245272),\n",
       " 'zp_W2': np.float32(-0.60532856),\n",
       " 'scale_b2': np.float32(0.9522776),\n",
       " 'zp_b2': np.float32(0.15996909)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_coefficients = {\n",
    "    \"scale_W1\": scale_W1,\n",
    "    \"zp_W1\": zp_W1,\n",
    "    \"scale_b1\": scale_b1,\n",
    "    \"zp_b1\": zp_b1,\n",
    "    \"scale_W2\": scale_W2,\n",
    "    \"zp_W2\": zp_W2,\n",
    "    \"scale_b2\": scale_b2,\n",
    "    \"zp_b2\": zp_b2\n",
    "}\n",
    "linear_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1149eaa5-4f9d-4fcb-ae77-8ee17a0c2fc6",
   "metadata": {},
   "source": [
    "Choosing the best model depends on the specific requirements of your task. \n",
    "\n",
    "For example, if we want to balance model accuracy described via `macro_avg_f1` and model storage efficiency, we can pick `Q_4bit` solution. \n",
    "\n",
    "If we need the fastest model possible with minimum memory consumption for resource-constrained electronics, `Q_2bit` is our choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca9cedd-d022-46bf-b858-a2f4417c48fa",
   "metadata": {},
   "source": [
    "That's it! We created a wine classifier with Numpy from scratch and applied asymmetric linear quantization!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd30800a-dc1e-446c-8df9-20fa964cb63c",
   "metadata": {},
   "source": [
    "### 1.2 Example: Pytorch implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab26b71-b3ef-44f7-b0f6-58c48216ccb9",
   "metadata": {},
   "source": [
    "#### Preparing neural network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "54ba772a-039e-4558-a367-661aa400e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNetTorch(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
    "        super(NNetTorch, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        z1 = self.layer1(x)\n",
    "        a1 = self.relu(z1)\n",
    "        z2 = self.layer2(a1)\n",
    "        return z2        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "89fc25ff-ccc2-4853-ae3a-59cffcaf467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set model parameters\n",
    "n_features = X.shape[1]             # 13 features, 13 table columns\n",
    "input_size = n_features             # Features are our input size of one sample\n",
    "hidden_size = 100                   # Hidden size is our hidden dimension. \n",
    "output_size = len(np.unique(y))     # Output size is defined via our categories\n",
    "\n",
    "# Set model training configuration\n",
    "epochs = 200     # Total epochs\n",
    "batch_size = 10  # How many samples we use in a mini-batch training\n",
    "lr = 0.1         # Learning rate is constant for simplicity\n",
    "eps = 1e-8       # Constant for numerical stability\n",
    "show_epochs = 10 # For verbose output\n",
    "train_size = len(y_train)\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f2c30c85-28a2-42ba-a733-f3a35345d48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Train loss: 9.005224227905273\n",
      "Epoch: 10. Train loss: 0.4637968838214874\n",
      "Epoch: 20. Train loss: 0.2039313018321991\n",
      "Epoch: 30. Train loss: 0.12359452247619629\n",
      "Epoch: 40. Train loss: 0.08653610199689865\n",
      "Epoch: 50. Train loss: 0.06568372249603271\n",
      "Epoch: 60. Train loss: 0.05258850008249283\n",
      "Epoch: 70. Train loss: 0.04365142062306404\n",
      "Epoch: 80. Train loss: 0.037142105400562286\n",
      "Epoch: 90. Train loss: 0.03222281485795975\n",
      "Epoch: 100. Train loss: 0.02839748002588749\n",
      "Epoch: 110. Train loss: 0.02533889375627041\n",
      "Epoch: 120. Train loss: 0.022840632125735283\n",
      "Epoch: 130. Train loss: 0.02076141908764839\n",
      "Epoch: 140. Train loss: 0.01901182532310486\n",
      "Epoch: 150. Train loss: 0.017512481659650803\n",
      "Epoch: 160. Train loss: 0.016218826174736023\n",
      "Epoch: 170. Train loss: 0.01508971955627203\n",
      "Epoch: 180. Train loss: 0.01409891713410616\n",
      "Epoch: 190. Train loss: 0.013219804503023624\n"
     ]
    }
   ],
   "source": [
    "model_torch = NNetTorch(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_torch.parameters(), lr=lr)\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  loss_accum = 0\n",
    "  for i in range(0, train_size, batch_size):\n",
    "      \n",
    "    X_batch = X_train_sc[i: i + batch_size, :]\n",
    "    y_batch = np.array(y_train_enc[i: i + batch_size, :].todense())\n",
    "    X_batch = torch.tensor(X_batch, dtype=torch.float32).to(device)\n",
    "    y_batch = torch.tensor(y_batch, dtype=torch.float32).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "      \n",
    "    y_pred = model_torch.forward(X_batch)\n",
    "    \n",
    "    loss = criterion(y_pred, y_batch)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_accum += loss\n",
    "      \n",
    "  loss_log.append(float(loss_accum.detach().numpy()))\n",
    "  if epoch % show_epochs == 0:\n",
    "    print(f\"Epoch: {epoch}. Train loss: {loss_accum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "005b4caf-675a-4836-b0de-104e89ac346a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 294,
       "width": 380
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(4 ,3))\n",
    "plt.plot(np.log(loss_log))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"log(Loss per epoch)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "67db6968-66aa-46a8-ac43-288485b292ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00         8\n",
      "     class_1       0.92      1.00      0.96        11\n",
      "     class_2       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_torch.eval()\n",
    "\n",
    "y_pred_test = torch.argmax(model_torch.forward(torch.tensor(X_test_sc, dtype=torch.float32, )), axis=1)\n",
    "print(classification_report(y_test, y_pred_test.numpy(), target_names=data.target_names))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "563e20e5-08a9-430a-ae72-4b2e75941dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NNetTorch(\n",
       "   (layer1): Linear(in_features=13, out_features=100, bias=True)\n",
       "   (layer2): Linear(in_features=100, out_features=3, bias=True)\n",
       "   (relu): ReLU()\n",
       " ),\n",
       " Linear(in_features=13, out_features=100, bias=True),\n",
       " Linear(in_features=100, out_features=3, bias=True),\n",
       " ReLU()]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in model_torch.modules()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c336684a-47ba-4afe-b2e2-36a2bafb9b60",
   "metadata": {},
   "source": [
    "In torch API we have model parameters representation `.weight` and `.bias` attributes in a layer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c15b2b97-7c6c-4c78-b28a-0e1cd3209b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_module = model_torch.get_submodule(\"layer1\")\n",
    "layer2_module = model_torch.get_submodule(\"layer2\")\n",
    "layer1_W, layer1_b = layer1_module.weight, layer1_module.bias\n",
    "layer2_W, layer2_b = layer2_module.weight, layer2_module.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0fb724e3-6ceb-4159-a9d7-9e82adc25e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model info:\n",
      "dim(W1): torch.Size([100, 13])\n",
      "dim(b1): torch.Size([100])\n",
      "dim(W2): torch.Size([3, 100])\n",
      "dim(b2): torch.Size([3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_torch_info = {\n",
    "    \"W1\": layer1_W.shape,\n",
    "    \"b1\": layer1_b.shape,\n",
    "    \"W2\": layer2_W.shape,\n",
    "    \"b2\": layer2_b.shape,\n",
    "}\n",
    "print(\"Model info:\\n\" + \"\".join([f\"dim({k}): {v}\\n\" for k, v in model_torch_info.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6b3c71-93a2-4533-bedc-9d7ad5d34d75",
   "metadata": {},
   "source": [
    "__Note about weight shapes__\n",
    "\n",
    "Let's recall that initial tabular data dimensions is `X.shape = (178, 13)` where 178 is the number of samples and 13 is the number of features in a dataset.\n",
    "\n",
    "In Numpy implementation we have a *mathematical* way of tensor dimensions representation which is `[in_features, out_features]`:\n",
    "\n",
    "    Model info:\n",
    "    dim(W1): (13, 100)\n",
    "    dim(b1): (1, 100)\n",
    "    dim(W2): (100, 3)\n",
    "    dim(b2): (1, 3)\n",
    "    \n",
    "In torch API dimensions order is `[out_features, in_features]`:\n",
    "\n",
    "    Model info:\n",
    "    dim(W1): torch.Size([100, 13])\n",
    "    dim(b1): torch.Size([100])\n",
    "    dim(W2): torch.Size([3, 100])\n",
    "    dim(b2): torch.Size([3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47db01aa-0a1d-4178-8e96-3ca0b9410180",
   "metadata": {},
   "source": [
    "#### Apply quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e39ce1-1a8b-4f51-beab-a37991b5a9ff",
   "metadata": {},
   "source": [
    "#### torch.ao.quantization API\n",
    "\n",
    "- __[October 2025]__\n",
    "    * torch.ao API for quantization is available with `torch<2.10`. Starting from `torch==2.10` torchao will be the main API for these operations.\n",
    "    * The details about API migration is in `DeprecationWarning` message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f06dac9-1a80-47a5-a237-9a9dcf61df71",
   "metadata": {},
   "source": [
    "In torch<2.10 weight only quantization is mainly supported with dynamic quantization where we actually have uantization for the activations happening on-the-fly (“dynamic”) during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "825791dd-0918-4c71-9201-f9ca37807733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38881/55647241.py:1: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  model_torch_8bit_quantized = torch.quantization.quantize_dynamic(\n"
     ]
    }
   ],
   "source": [
    "model_torch_8bit_quantized = torch.quantization.quantize_dynamic(\n",
    "    model=model_torch,  \n",
    "    qconfig_spec={torch.nn.Linear}, \n",
    "    dtype=torch.qint8,\n",
    "    inplace=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b5e03e10-e18a-4e4a-9e26-28d9f79a3c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNetTorch(\n",
       "  (layer1): DynamicQuantizedLinear(in_features=13, out_features=100, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "  (layer2): DynamicQuantizedLinear(in_features=100, out_features=3, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch_8bit_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "254b5f8d-a35c-45dd-b096-466cbe444fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00         8\n",
      "     class_1       0.92      1.00      0.96        11\n",
      "     class_2       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_torch_8bit_quantized.eval()\n",
    "y_pred_test = torch.argmax(model_torch_8bit_quantized.forward(torch.tensor(X_test_sc, dtype=torch.float32, )), axis=1)\n",
    "print(classification_report(y_test, y_pred_test.numpy(), target_names=data.target_names))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6db9c1-5116-4433-8c42-4cf7c23ddb8a",
   "metadata": {},
   "source": [
    "Now we quantize weights and activations. This is a static quantization which means we need to add quantize and dequantize operations into our model. To do that. we add `QuantStub` and `DeQuantStub` layers.\n",
    "\n",
    "Note: About 100 mini-batches of representative data are sufficient to calibrate.\n",
    "\n",
    "See details: https://docs.pytorch.org/docs/stable/quantization-support.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7dffc69f-c246-4daa-8578-a2aa1818655a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38881/574239775.py:19: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  model_torch_prepared = torch.quantization.prepare(model_torch_with_stubs, inplace=False)\n",
      "/tmp/ipykernel_38881/574239775.py:32: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  model_torch_8bit_quantized = torch.quantization.convert(model_torch_prepared)\n"
     ]
    }
   ],
   "source": [
    "model_torch_with_stubs = nn.Sequential(\n",
    "    torch.quantization.QuantStub(), \n",
    "    model_torch, \n",
    "    torch.quantization.DeQuantStub()\n",
    ")\n",
    "\n",
    "model_torch_with_stubs.qconfig = torch.quantization.QConfig(\n",
    "    activation=torch.quantization.MinMaxObserver.with_args(\n",
    "        qscheme=torch.per_tensor_affine,  # Affine / Asymmetric\n",
    "        dtype=torch.quint8,\n",
    "        reduce_range=False\n",
    "    ),\n",
    "    weight=torch.quantization.MinMaxObserver.with_args(\n",
    "        dtype=torch.qint8,\n",
    "        qscheme=torch.per_tensor_affine  # Affine / Asymmetric\n",
    "    )\n",
    ")\n",
    "\n",
    "model_torch_prepared = torch.quantization.prepare(model_torch_with_stubs, inplace=False)\n",
    "\n",
    "# We need to calibrate our model a bit.\n",
    "# It means that we should collect statistics about our input data distribution in order to properly modify activations. \n",
    "# Since we do not have calibration dataset, we will use scaled train susbet params to generate feature vectors.\n",
    "\n",
    "N_calib = 100\n",
    "with torch.no_grad():\n",
    "    for _ in range(N_calib):\n",
    "        sample_input = np.random.normal(loc=X_train_sc.mean(axis=0), scale=1.)\n",
    "        tensor_input = torch.tensor(sample_input, dtype=torch.float32)\n",
    "        model_torch_prepared(tensor_input)\n",
    "\n",
    "model_torch_8bit_quantized = torch.quantization.convert(model_torch_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "886fa2fd-7823-4f88-91f3-09eb21030fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Quantize(scale=tensor([0.0271]), zero_point=tensor([130]), dtype=torch.quint8)\n",
       "  (1): NNetTorch(\n",
       "    (layer1): QuantizedLinear(in_features=13, out_features=100, scale=0.024561908096075058, zero_point=123, qscheme=torch.per_tensor_affine)\n",
       "    (layer2): QuantizedLinear(in_features=100, out_features=3, scale=0.07960879802703857, zero_point=103, qscheme=torch.per_tensor_affine)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (2): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch_8bit_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "35d34d91-5ac4-431e-9d94-ccfdb57ccfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00         8\n",
      "     class_1       0.92      1.00      0.96        11\n",
      "     class_2       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_torch_8bit_quantized.eval()\n",
    "y_pred_test = torch.argmax(model_torch_8bit_quantized.forward(torch.tensor(X_test_sc, dtype=torch.float32)), axis=1)\n",
    "print(classification_report(y_test, y_pred_test.numpy(), target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91783af5-923b-45f7-969c-843f00ee5bff",
   "metadata": {},
   "source": [
    "#### torchao API\n",
    "\n",
    "See: https://docs.pytorch.org/ao/stable/static_quantization.html\n",
    "\n",
    "There are several predefined configs for torch models quantization as well as detailed examle in official torchao doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c4763031-f6d5-4460-848a-dba756864189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from torchao.quantization import Int8WeightOnlyConfig, Int4WeightOnlyConfig\n",
    "from torchao.quantization import Int8DynamicActivationInt4WeightConfig\n",
    "from torchao.quantization import Float8StaticActivationFloat8WeightConfig \n",
    "\n",
    "from torchao.core.config import AOBaseConfig\n",
    "from torchao.quantization import quantize_\n",
    "from torchao.quantization.quant_api import _replace_with_custom_fn_if_matches_filter\n",
    "from torchao.dtypes import to_affine_quantized_intx_static\n",
    "from torchao.quantization.observer import AffineQuantizedMinMaxObserver\n",
    "from torchao.quantization.granularity import PerTensor, PerAxis\n",
    "from torchao.quantization.quant_primitives import MappingType\n",
    "from torchao.quantization.transform_module import register_quantize_module_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6ac0bad3-8d84-4ffa-b75b-51a6a161c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_obs = AffineQuantizedMinMaxObserver(\n",
    "    MappingType.ASYMMETRIC, # ASYMMETRIC or SYMMETRIC\n",
    "    torch.uint8,\n",
    "    granularity=PerTensor(),\n",
    "    eps=torch.finfo(torch.float32).eps,\n",
    "    scale_dtype=torch.float32,\n",
    "    zero_point_dtype=torch.float32,\n",
    ")\n",
    "\n",
    "weight_obs = AffineQuantizedMinMaxObserver(\n",
    "    MappingType.ASYMMETRIC,  # ASYMMETRIC or SYMMETRIC\n",
    "    torch.uint8,\n",
    "    granularity=PerAxis(axis=0),\n",
    "    eps=torch.finfo(torch.float32).eps,\n",
    "    scale_dtype=torch.float32,\n",
    "    zero_point_dtype=torch.float32,\n",
    ")\n",
    "\n",
    "class ObservedLinear(torch.nn.Linear):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        act_obs: torch.nn.Module,\n",
    "        weight_obs: torch.nn.Module,\n",
    "        bias: bool = True,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "    ):\n",
    "        super().__init__(in_features, out_features, bias, device, dtype)\n",
    "        self.act_obs = act_obs\n",
    "        self.weight_obs = weight_obs\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        observed_input = self.act_obs(input)\n",
    "        observed_weight = self.weight_obs(self.weight)\n",
    "        return F.linear(observed_input, observed_weight, self.bias)\n",
    "\n",
    "    @classmethod\n",
    "    def from_float(cls, float_linear, act_obs, weight_obs):\n",
    "        observed_linear = cls(\n",
    "            float_linear.in_features,\n",
    "            float_linear.out_features,\n",
    "            act_obs,\n",
    "            weight_obs,\n",
    "            False,\n",
    "            device=float_linear.weight.device,\n",
    "            dtype=float_linear.weight.dtype,\n",
    "        )\n",
    "        observed_linear.weight = float_linear.weight\n",
    "        observed_linear.bias = float_linear.bias\n",
    "        return observed_linear\n",
    "\n",
    "def insert_observers_(model, act_obs, weight_obs):\n",
    "    _is_linear = lambda m, fqn: isinstance(m, torch.nn.Linear)\n",
    "\n",
    "    def replacement_fn(m):\n",
    "        copied_act_obs = copy.deepcopy(act_obs)\n",
    "        copied_weight_obs = copy.deepcopy(weight_obs)\n",
    "        return ObservedLinear.from_float(m, copied_act_obs, copied_weight_obs)\n",
    "\n",
    "    _replace_with_custom_fn_if_matches_filter(model, replacement_fn, _is_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6fcfa3f0-fbe1-43ef-bf15-15e951ffcfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_torch_ao = copy.deepcopy(model_torch)\n",
    "insert_observers_(model_torch_ao, act_obs, weight_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1e0b14a3-39eb-471a-8048-c5853c9ddcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNetTorch(\n",
       "  (layer1): ObservedLinear(\n",
       "    in_features=13, out_features=100, bias=True\n",
       "    (act_obs): AffineQuantizedMinMaxObserver()\n",
       "    (weight_obs): AffineQuantizedMinMaxObserver()\n",
       "  )\n",
       "  (layer2): ObservedLinear(\n",
       "    in_features=100, out_features=3, bias=True\n",
       "    (act_obs): AffineQuantizedMinMaxObserver()\n",
       "    (weight_obs): AffineQuantizedMinMaxObserver()\n",
       "  )\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch_ao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a91d54ea-c63e-4cf0-b6e6-a32f61b62d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_calib = 100\n",
    "with torch.no_grad():\n",
    "    for _ in range(N_calib):\n",
    "        sample_input = np.random.normal(loc=X_train_sc.mean(axis=0), scale=1.)\n",
    "        tensor_input = torch.tensor(sample_input, dtype=torch.float32)\n",
    "        model_torch_ao(tensor_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a0da89d8-46ea-40fa-9e61-9faa3a57de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedLinear(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        act_obs: torch.nn.Module,\n",
    "        weight_obs: torch.nn.Module,\n",
    "        weight: torch.Tensor,\n",
    "        bias: torch.Tensor,\n",
    "        target_dtype: torch.dtype,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.act_scale, self.act_zero_point = act_obs.calculate_qparams()\n",
    "        weight_scale, weight_zero_point = weight_obs.calculate_qparams()\n",
    "        assert weight.dim() == 2\n",
    "        block_size = (1, weight.shape[1])\n",
    "        self.target_dtype = target_dtype\n",
    "        self.bias = bias\n",
    "        self.qweight = to_affine_quantized_intx_static(\n",
    "            weight, weight_scale, weight_zero_point, block_size, self.target_dtype\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        block_size = input.shape\n",
    "        qinput = to_affine_quantized_intx_static(\n",
    "            input,\n",
    "            self.act_scale,\n",
    "            self.act_zero_point,\n",
    "            block_size,\n",
    "            self.target_dtype,\n",
    "        )\n",
    "        return F.linear(qinput, self.qweight, self.bias)\n",
    "\n",
    "    @classmethod\n",
    "    def from_observed(cls, observed_linear, target_dtype):\n",
    "        quantized_linear = cls(\n",
    "            observed_linear.in_features,\n",
    "            observed_linear.out_features,\n",
    "            observed_linear.act_obs,\n",
    "            observed_linear.weight_obs,\n",
    "            observed_linear.weight,\n",
    "            observed_linear.bias,\n",
    "            target_dtype,\n",
    "        )\n",
    "        return quantized_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "95c7d0b4-eec2-4b02-bd46-ff15f82832cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class StaticQuantConfig(AOBaseConfig):\n",
    "    target_dtype: torch.dtype\n",
    "\n",
    "@register_quantize_module_handler(StaticQuantConfig)\n",
    "def _apply_static_quant(\n",
    "    module: torch.nn.Module,\n",
    "    config: StaticQuantConfig,\n",
    "):\n",
    "    \"\"\"\n",
    "    Define a transformation associated with `StaticQuantConfig`.\n",
    "    This is called by `quantize_`, not by the user directly.\n",
    "    \"\"\"\n",
    "    return QuantizedLinear.from_observed(module, config.target_dtype)\n",
    "\n",
    "# filter function to identify which modules to swap\n",
    "is_observed_linear = lambda m, fqn: isinstance(m, ObservedLinear)\n",
    "\n",
    "# perform static quantization\n",
    "quantize_(model_torch_ao, StaticQuantConfig(torch.uint8), is_observed_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d45275c4-1c55-4ce6-9181-01a41401a226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNetTorch(\n",
       "  (layer1): QuantizedLinear()\n",
       "  (layer2): QuantizedLinear()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch_ao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "39eaffb9-d0e3-418c-9f6b-36a6afbd55d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00         8\n",
      "     class_1       0.92      1.00      0.96        11\n",
      "     class_2       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_torch_ao.eval()\n",
    "y_pred_test = torch.argmax(model_torch_ao.forward(torch.tensor(X_test_sc, dtype=torch.float32)), axis=1)\n",
    "print(classification_report(y_test, y_pred_test.numpy(), target_names=data.target_names))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "34ed1ff6-9340-4a55-a3f9-34573f95f891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AffineQuantizedTensor(tensor_impl=PlainAQTTensorImpl(data=tensor([[ 70, 128,  49,  ...,  83, 200,   3],\n",
       "        [  0,  36,  83,  ..., 255,  57, 133],\n",
       "        [ 53, 234, 243,  ...,  22, 116,  23],\n",
       "        ...,\n",
       "        [119, 167, 233,  ...,  39,   0, 223],\n",
       "        [180,  92, 111,  ..., 220, 145,   0],\n",
       "        [ 25,  66,  17,  ..., 242, 140,   5]], dtype=torch.uint8)... , scale=tensor([0.0018, 0.0022, 0.0020, 0.0017, 0.0024, 0.0022, 0.0026, 0.0025, 0.0021,\n",
       "        0.0021, 0.0012, 0.0020, 0.0020, 0.0022, 0.0022, 0.0022, 0.0030, 0.0017,\n",
       "        0.0023, 0.0018, 0.0027, 0.0036, 0.0027, 0.0019, 0.0019, 0.0020, 0.0024,\n",
       "        0.0016, 0.0019, 0.0019, 0.0022, 0.0024, 0.0024, 0.0022, 0.0023, 0.0026,\n",
       "        0.0024, 0.0024, 0.0014, 0.0026, 0.0019, 0.0020, 0.0022, 0.0021, 0.0021,\n",
       "        0.0031, 0.0025, 0.0022, 0.0020, 0.0023, 0.0016, 0.0015, 0.0027, 0.0023,\n",
       "        0.0023, 0.0018, 0.0024, 0.0029, 0.0026, 0.0025, 0.0023, 0.0028, 0.0023,\n",
       "        0.0016, 0.0031, 0.0020, 0.0024, 0.0022, 0.0022, 0.0020, 0.0029, 0.0025,\n",
       "        0.0023, 0.0024, 0.0024, 0.0027, 0.0024, 0.0026, 0.0028, 0.0020, 0.0024,\n",
       "        0.0019, 0.0023, 0.0024, 0.0026, 0.0022, 0.0015, 0.0022, 0.0018, 0.0022,\n",
       "        0.0029, 0.0024, 0.0019, 0.0025, 0.0018, 0.0021, 0.0025, 0.0022, 0.0026,\n",
       "        0.0024])... , zero_point=tensor([133., 105., 122.,  97., 137., 139., 103., 101., 117.,  84., 173., 114.,\n",
       "        121., 109., 149., 132., 151., 159., 161., 114., 128., 120., 117., 122.,\n",
       "        134., 134., 151.,  97., 139., 146., 124., 110., 122., 103., 174., 122.,\n",
       "        181., 146., 158., 131.,  92., 113., 111., 111., 148., 134., 122., 150.,\n",
       "        106.,  87., 148.,  55., 129., 133., 135.,  96., 162., 131., 142., 101.,\n",
       "        149., 148., 125., 188., 134., 129., 143., 127., 151., 130., 128., 137.,\n",
       "        129.,  96., 139., 128., 113., 119., 130.,  89., 100., 146., 122., 130.,\n",
       "        138., 137., 106., 126., 117., 107., 121., 132.,  99., 126., 165., 185.,\n",
       "        101., 162., 141., 119.])... , _layout=PlainLayout()), block_size=(1, 13), shape=torch.Size([100, 13]), device=cpu, dtype=torch.float32, requires_grad=False)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch_ao.get_submodule(\"layer1\").qweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3d220a4a-fb1e-4c36-8f3d-75859f6a8551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1813,  0.1357,  0.2624,  0.3053,  0.0892,  0.1623,  0.2179,  0.3732,\n",
       "        -0.2232,  0.1446, -0.1695, -0.0876, -0.2863, -0.1848,  0.2870, -0.0086,\n",
       "         0.2643, -0.2374,  0.0596,  0.1793,  0.1847,  0.2727,  0.3992, -0.2607,\n",
       "        -0.1017, -0.1991,  0.1971, -0.0128, -0.0442,  0.1727,  0.0953,  0.2078,\n",
       "        -0.0858, -0.0805,  0.1546, -0.0710,  0.1670, -0.0221,  0.1278, -0.1898,\n",
       "        -0.1591, -0.0521,  0.1075, -0.0577,  0.2702,  0.3092,  0.1640,  0.2382,\n",
       "        -0.2314,  0.2611, -0.1818,  0.3401,  0.2177,  0.1151,  0.2238, -0.0037,\n",
       "        -0.1180,  0.0575,  0.2661,  0.2660, -0.2246, -0.0440,  0.0489, -0.0977,\n",
       "        -0.1266, -0.2183,  0.0272, -0.2230,  0.1602, -0.0068,  0.1271,  0.1193,\n",
       "         0.1665,  0.2376,  0.0505,  0.2689,  0.2189,  0.0073,  0.3055, -0.2426,\n",
       "         0.1149,  0.2373,  0.3551,  0.3098,  0.2602, -0.1526, -0.1691,  0.0402,\n",
       "         0.2435,  0.0259,  0.2799,  0.3631,  0.2337, -0.0659, -0.0808,  0.2157,\n",
       "         0.0274,  0.1854,  0.3029, -0.1879], requires_grad=True)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch_ao.get_submodule(\"layer1\").bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5e9e8efc-e5f8-4895-8443-ccaa6eea98ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1813,  0.1357,  0.2624,  0.3053,  0.0892,  0.1623,  0.2179,  0.3732,\n",
       "        -0.2232,  0.1446, -0.1695, -0.0876, -0.2863, -0.1848,  0.2870, -0.0086,\n",
       "         0.2643, -0.2374,  0.0596,  0.1793,  0.1847,  0.2727,  0.3992, -0.2607,\n",
       "        -0.1017, -0.1991,  0.1971, -0.0128, -0.0442,  0.1727,  0.0953,  0.2078,\n",
       "        -0.0858, -0.0805,  0.1546, -0.0710,  0.1670, -0.0221,  0.1278, -0.1898,\n",
       "        -0.1591, -0.0521,  0.1075, -0.0577,  0.2702,  0.3092,  0.1640,  0.2382,\n",
       "        -0.2314,  0.2611, -0.1818,  0.3401,  0.2177,  0.1151,  0.2238, -0.0037,\n",
       "        -0.1180,  0.0575,  0.2661,  0.2660, -0.2246, -0.0440,  0.0489, -0.0977,\n",
       "        -0.1266, -0.2183,  0.0272, -0.2230,  0.1602, -0.0068,  0.1271,  0.1193,\n",
       "         0.1665,  0.2376,  0.0505,  0.2689,  0.2189,  0.0073,  0.3055, -0.2426,\n",
       "         0.1149,  0.2373,  0.3551,  0.3098,  0.2602, -0.1526, -0.1691,  0.0402,\n",
       "         0.2435,  0.0259,  0.2799,  0.3631,  0.2337, -0.0659, -0.0808,  0.2157,\n",
       "         0.0274,  0.1854,  0.3029, -0.1879], requires_grad=True)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch.get_submodule(\"layer1\").bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5ce4cb-5d74-4305-a762-34aed724c047",
   "metadata": {},
   "source": [
    "As we can see biases were not quantized with this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5534c8b6-aefd-4662-b8bd-851da918a988",
   "metadata": {},
   "source": [
    "With predefined config static weight quantization is very straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "85c469e4-fb04-4942-b447-df8099854856",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_torch_ao_8bit = copy.deepcopy(model_torch)\n",
    "quantize_(model_torch_ao_8bit, Int8WeightOnlyConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "75d2c764-5182-4253-9610-c80496e7e992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNetTorch(\n",
       "  (layer1): Linear(in_features=13, out_features=100, weight=AffineQuantizedTensor(shape=torch.Size([100, 13]), block_size=(1, 13), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None))\n",
       "  (layer2): Linear(in_features=100, out_features=3, weight=AffineQuantizedTensor(shape=torch.Size([3, 100]), block_size=(1, 100), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None))\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch_ao_8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1386662a-f0bc-4bb5-82ba-fff63f88a2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AffineQuantizedTensor(tensor_impl=PlainAQTTensorImpl(data=tensor([[ -61,   -5,  -80,  ...,  -48,   65, -125],\n",
       "        [ -90,  -59,  -19,  ...,  127,  -41,   23],\n",
       "        [ -66,  107,  115,  ...,  -95,   -6,  -94],\n",
       "        ...,\n",
       "        [ -34,    4,   56,  ...,  -97, -128,   48],\n",
       "        [  35,  -44,  -27,  ...,   71,    4, -128],\n",
       "        [ -88,  -50,  -96,  ...,  115,   20, -107]], dtype=torch.int8)... , scale=tensor([0.0018, 0.0026, 0.0021, 0.0022, 0.0026, 0.0024, 0.0031, 0.0030, 0.0023,\n",
       "        0.0028, 0.0017, 0.0022, 0.0021, 0.0025, 0.0026, 0.0023, 0.0035, 0.0021,\n",
       "        0.0029, 0.0020, 0.0027, 0.0038, 0.0029, 0.0020, 0.0020, 0.0021, 0.0028,\n",
       "        0.0020, 0.0021, 0.0022, 0.0022, 0.0027, 0.0025, 0.0027, 0.0031, 0.0027,\n",
       "        0.0034, 0.0028, 0.0017, 0.0027, 0.0024, 0.0022, 0.0024, 0.0023, 0.0024,\n",
       "        0.0033, 0.0026, 0.0026, 0.0023, 0.0030, 0.0018, 0.0023, 0.0027, 0.0024,\n",
       "        0.0024, 0.0022, 0.0030, 0.0030, 0.0029, 0.0030, 0.0027, 0.0032, 0.0023,\n",
       "        0.0024, 0.0032, 0.0020, 0.0027, 0.0022, 0.0026, 0.0020, 0.0029, 0.0027,\n",
       "        0.0023, 0.0030, 0.0026, 0.0027, 0.0027, 0.0027, 0.0028, 0.0026, 0.0029,\n",
       "        0.0022, 0.0024, 0.0025, 0.0028, 0.0024, 0.0018, 0.0022, 0.0020, 0.0025,\n",
       "        0.0030, 0.0025, 0.0024, 0.0026, 0.0024, 0.0031, 0.0030, 0.0027, 0.0029,\n",
       "        0.0025])... , zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0])... , _layout=PlainLayout()), block_size=(1, 13), shape=torch.Size([100, 13]), device=cpu, dtype=torch.float32, requires_grad=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch_ao_8bit.get_submodule(\"layer1\").weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b164bd68-71f2-431d-8544-2cc5d54bbcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1813,  0.1357,  0.2624,  0.3053,  0.0892,  0.1623,  0.2179,  0.3732,\n",
       "        -0.2232,  0.1446, -0.1695, -0.0876, -0.2863, -0.1848,  0.2870, -0.0086,\n",
       "         0.2643, -0.2374,  0.0596,  0.1793,  0.1847,  0.2727,  0.3992, -0.2607,\n",
       "        -0.1017, -0.1991,  0.1971, -0.0128, -0.0442,  0.1727,  0.0953,  0.2078,\n",
       "        -0.0858, -0.0805,  0.1546, -0.0710,  0.1670, -0.0221,  0.1278, -0.1898,\n",
       "        -0.1591, -0.0521,  0.1075, -0.0577,  0.2702,  0.3092,  0.1640,  0.2382,\n",
       "        -0.2314,  0.2611, -0.1818,  0.3401,  0.2177,  0.1151,  0.2238, -0.0037,\n",
       "        -0.1180,  0.0575,  0.2661,  0.2660, -0.2246, -0.0440,  0.0489, -0.0977,\n",
       "        -0.1266, -0.2183,  0.0272, -0.2230,  0.1602, -0.0068,  0.1271,  0.1193,\n",
       "         0.1665,  0.2376,  0.0505,  0.2689,  0.2189,  0.0073,  0.3055, -0.2426,\n",
       "         0.1149,  0.2373,  0.3551,  0.3098,  0.2602, -0.1526, -0.1691,  0.0402,\n",
       "         0.2435,  0.0259,  0.2799,  0.3631,  0.2337, -0.0659, -0.0808,  0.2157,\n",
       "         0.0274,  0.1854,  0.3029, -0.1879], requires_grad=True)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch_ao_8bit.get_submodule(\"layer1\").bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ce6c4-8538-45c2-8426-2bd3797eb6ac",
   "metadata": {},
   "source": [
    "Biases are not quantized here as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70ebdf-da80-4639-9ed3-651148ec17bb",
   "metadata": {},
   "source": [
    "### Example 2. Image classifier with convolutional neural network. CIFAR-10 \n",
    "\n",
    "In this examaple we will classify images using [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b275eb50-6729-4316-b1f2-214cac3ff846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6278a9f-d07b-427c-9ec8-7af227f93d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e258ee7e-1a4d-4162-afe6-0139372888c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3bca52-36e8-4f51-83a5-17f1a4cb2ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5041aa72-5ffb-431c-a1f0-b2df746818be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd6883a7-32e5-46d8-81de-5c86cd0ec176",
   "metadata": {},
   "source": [
    "### Pytorch implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a12ca96-3a4f-48f3-a612-491f6f606524",
   "metadata": {},
   "source": [
    "#### Preparing neural network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec54b210-5f0b-4849-93f0-8612bd119873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24502fe8-d7c6-495a-94fe-8e7608c69735",
   "metadata": {},
   "source": [
    "#### Apply quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfbace2-f789-42fd-ba28-e5ee9e165489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b624544-1e61-4858-bfd2-c1fe5c24bf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b55d5-2c04-499e-8330-182344939222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20277f3d-50af-4a67-97fa-4e028affc3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f03c02-b556-4b1e-b5d5-a7fe9aeb6a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "148bc238-61de-4fa4-a4c1-6cf7bc336789",
   "metadata": {},
   "source": [
    "These examples  mainly cover  __weights only__ quantization and is called __post-training quantization, PTQ__.\n",
    "\n",
    "Remember that we can also:\n",
    "1. Quantize __weights and activations altogether__. To do that we need a calibration dataset for activations containing examples expected in a production environment.\n",
    "2. Consider __Quantization Aware Training, QAT__ for a higher accuracy. Generally, this approach yields higher results but requires much more resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e540fd6-d2f0-43d6-be7e-543b806526fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb395a7-920c-4270-a8ea-7f3e95c54abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
